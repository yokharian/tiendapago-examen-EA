{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/drapaiton/.cache/pypoetry/virtualenvs/tiendapago-examen-ea-xYsG0OIB-py3.9/lib/python3.9/site-packages (1.3.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/drapaiton/.cache/pypoetry/virtualenvs/tiendapago-examen-ea-xYsG0OIB-py3.9/lib/python3.9/site-packages (from pandas) (1.21.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/drapaiton/.cache/pypoetry/virtualenvs/tiendapago-examen-ea-xYsG0OIB-py3.9/lib/python3.9/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/drapaiton/.cache/pypoetry/virtualenvs/tiendapago-examen-ea-xYsG0OIB-py3.9/lib/python3.9/site-packages (from pandas) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/drapaiton/.cache/pypoetry/virtualenvs/tiendapago-examen-ea-xYsG0OIB-py3.9/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 21.2.1 is available.\r\n",
      "You should consider upgrading via the '/home/drapaiton/.cache/pypoetry/virtualenvs/tiendapago-examen-ea-xYsG0OIB-py3.9/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as DaFe\n",
    "\n",
    "CUSTOMERS_FILE_PATH = \"Customers.csv\"\n",
    "TRANSACTIONS_FILE_PATH = 'Transactions.csv'\n",
    "DISTRIBUTOR_FILE_PATH = 'Distributor.csv'\n",
    "\n",
    "TRANSACTION_AMOUNT_COLUMN = 'TransactionAmount'\n",
    "DISTRIBUTOR_ID_COLUMN = 'DistributionCenterID'\n",
    "CUSTOMER_ID_COLUMN = 'CustomerID'\n",
    "DATE_COLUMN = 'Date'\n",
    "\n",
    "DATE_FORMAT = '%m/%d/%Y %H:%M'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Crear procesos de integración de datos que extraigan de los archivos insumos y generen\n",
    "las transformaciones necesarias para un modelo de Business Intelligence y Data\n",
    "Warehouse.\n",
    "\n",
    "Empresa: Bytelian SA de CV\n",
    "\"\"\"\n",
    "\n",
    "def integrate_bi_input_files() -> DaFe:\n",
    "    \"\"\"generate a big DaFe to calculate easier, as this file grows strategy should be modified\n",
    "    with chunk iteration, date iteration, unique client isolation  etc...\"\"\"\n",
    "    try:\n",
    "        customers_df = pd.read_csv(CUSTOMERS_FILE_PATH)\n",
    "        transactions_df = pd.read_csv(TRANSACTIONS_FILE_PATH)\n",
    "        distributor_df = pd.read_csv(DISTRIBUTOR_FILE_PATH)\n",
    "\n",
    "        df = customers_df.join(transactions_df.set_index(CUSTOMER_ID_COLUMN), on=CUSTOMER_ID_COLUMN)\n",
    "        if df.empty:\n",
    "            FILES_TRIED_TO_JOIN = [CUSTOMERS_FILE_PATH,TRANSACTIONS_FILE_PATH]\n",
    "            raise ValueError(f\"these files couldn't be merged {FILES_TRIED_TO_JOIN}\")\n",
    "\n",
    "        df = df.join(distributor_df.set_index(DISTRIBUTOR_ID_COLUMN), on=DISTRIBUTOR_ID_COLUMN)\n",
    "        if df.empty:\n",
    "            FILES_TRIED_TO_JOIN = [[CUSTOMERS_FILE_PATH,TRANSACTIONS_FILE_PATH],DISTRIBUTOR_FILE_PATH]\n",
    "            raise ValueError(f\"these files couldn't be merged {FILES_TRIED_TO_JOIN}\")\n",
    "\n",
    "        # clean empty indexes (this should filter wrong data written at original file)\n",
    "        df[CUSTOMER_ID_COLUMN] = df[CUSTOMER_ID_COLUMN].dropna()\n",
    "        df[DISTRIBUTOR_ID_COLUMN] = df[DISTRIBUTOR_ID_COLUMN].dropna()\n",
    "\n",
    "        # date parse\n",
    "        df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], format=DATE_FORMAT, errors='ignore')\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"couldn't parse {DATE_COLUMN=}\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def dag_bytelian_transactions_pipeline():\n",
    "    \"\"\"generate a big DaFe to calculate easier, as this file grows strategy should be modified\n",
    "    with chunk iteration, date iteration, unique client isolation  etc...\"\"\"\n",
    "    return integrate_bi_input_files()\n",
    "\n",
    "dag_bytelian_transactions_pipeline()\\\n",
    "    .to_csv('pipeline_results.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n2. Previo a un análisis de los datos, crear un modelo de Business Intelligence\\na nivel analítico para el área comercial.\\n'"
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. Previo a un análisis de los datos, crear un modelo de Business Intelligence\n",
    "a nivel analítico para el área comercial.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. Calcular 2 métricas (monto colocado y número transacciones) donde:\n",
    "a. Monto Colocado es la suma de la transacción (transaction amount).\n",
    "b. Número de transacciones es el conteo de las transacciones totales.\n",
    "\"\"\"\n",
    "\n",
    "def calculate_sum_count_metrics(\n",
    "    df: DaFe,\n",
    "    output_sum_column,\n",
    "    output_count_column,\n",
    "    parent_column=CUSTOMER_ID_COLUMN,\n",
    "    children_column=TRANSACTION_AMOUNT_COLUMN,\n",
    "):\n",
    "    return (\n",
    "        df[[parent_column, children_column]]\n",
    "        .groupby(parent_column)\n",
    "        .agg([\"sum\", \"count\"])\n",
    "        .reset_index()\n",
    "        .set_axis(\n",
    "            [parent_column, output_sum_column, output_count_column], axis=\"columns\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "full_df = dag_bytelian_transactions_pipeline()\n",
    "calculate_sum_count_metrics(full_df, \"Monto Colocado\", \"Número de transacciones\")\\\n",
    "    .to_excel('two_metrics.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. Proponer y justificar 3 métricas, que creas son importantes para la toma de decisiones del\n",
    "gerente Hugo Montoya.\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Generar un tablero de control que muestre los principales indicadores de una forma\n",
    "amigable para que el gerente pueda tomar decisiones de una manera eficaz y sencilla en\n",
    "diferentes puntos del tiempo.\n",
    "\n",
    "NOTA: Nuestra empresa necesita de un tablero de control que muestre los\n",
    "principales indicadores (5) para la correcta toma de decisiones del\n",
    "gerente comercial Hugo Montoya.\n",
    "\"\"\"\n",
    "\n",
    "full_df = dag_bytelian_transactions_pipeline()\n",
    "\"\"\"i would rather prefer to iterate thru months,\n",
    "but as dataset size is micro, daily is more explanatory\"\"\"\n",
    "def customer_with_higher_transaction_amount_sum_per_day(my_df: DaFe) -> DaFe:\n",
    "    df = my_df.copy()\n",
    "    # shrink hours minutes seconds, to group only days\n",
    "    df[DATE_COLUMN] = df[DATE_COLUMN].dt.date\n",
    "    return (\n",
    "        df[[DATE_COLUMN,CUSTOMER_ID_COLUMN,TRANSACTION_AMOUNT_COLUMN]]\n",
    "        .groupby([DATE_COLUMN,CUSTOMER_ID_COLUMN],as_index=False)\n",
    "        .sum()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "customer_with_higher_transaction_amount_sum_per_day(full_df)\\\n",
    "    .drop(columns=CUSTOMER_ID_COLUMN)\\\n",
    "    .describe()\\"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}